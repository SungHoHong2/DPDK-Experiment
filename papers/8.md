### [DPDK-based Improvement of Packet Forwarding](https://www.itm-conferences.org/articles/itmconf/pdf/2016/02/itmconf_ita2016_01009.pdf)

- **problem**
  - High-speed network packet forwarding system plays a vital role in many fields, such as packet analysis, virus detection and traffic management.
  - Universal NIC runs into a big bottleneck in many aspects, such as data buffering, packet copy and frequent interruptions which causes huge overhead
  - For the host, it causes excessive consumption of the computing, storage, I/O overhead which is too large to meet the requirements of line-speed data capture and handling on the Gigabit link.

- **solution**
  - In this paper, we analyze the key technologies of DPDK, and take advantage of DPDK framework to build a packet forwarding system.
  - In the process of DMA transfer,DPDK needs to send descriptor separately, which wasted PCIe bandwidth, resulting in a performance bottleneck, therefore we propose a new method named Minimum Overhead DMA to solve this problem.

- **conclusion**
 - proposed the Minimum Overhead DMA mode using descriptors and packets sending together to improve the utilization of PCIe bandwidth
 - Experimental results show that MODMA can effectively solve the performance bottleneck of DPDK packet forwarding
 - make the system performance, especially in condition of the 64 byte packets improve significantly

<br>


- **Definition of DPDK**
  - In order to reduce the cost of data copies and complexity of kernel protocol stack process
  - data plane development kit
  - provide programmers a simple and complete fast packet processing framework
  - Users can create prototypes or add their own protocol stack according to their requirements.
  - DPDK achieves a zero-copy, large pages, lock-free buffer queue,


<br>

- **Memory Management**
  - uses a large space to form a `memory pool`
  - `memory pool` is an object allocator with fix size (storing packets entities require memory alignment to ensure that the object in memory allocated in different memory channels)
  - memory pool is identified by name, and uses a ring to manage free objects.
  - In case of `multiple consumers`, you can use pipe-line mode to access the ring
  - DPDK uses CAS (compare and swap) between multiple threads so that they can access the ring (lock-free queue) without using lock, which will greatly reduce the huge overhead of lock competition.
    - `compare and swap` is  If ring->prod_head is different to local variable prod_head, the CAS operation fails, and the code restarts at first step.
    - `Nonblocking algorithms` generally scale better because they have shorter `critical sections` than lock-based algorithms.
  - use of large pages can significantly reduce the frequency of TLB miss and page fault, reducing unnecessary consumption of memory access

<br>

- **Implementation of Zero Copy**
  - When packets arrive, it will trigger an interrupt; packet is copied from the buffer in NIC to the kernel buffer queue
  - passes through the kernel then the packet copis from the kernel buffer to the user space,
  - Date flow contains multiple copies of data, resulting in a significant reduction in performance.
  - the two newly written data copy operations are inconsistent with localized features, it basically does not have cache hit; therefore the memory access efficiency is very low
  - Zero-copy maps kernel space to user space, the underlying driver transfer data directly to the user space through DMA

- **Poll mode driver**
  - It will map the NIC register to user space,therefor users can directly access the NIC registers and that allows user-space driver
  - In case of the arrival of high-speed packets, interrupt overhead will be enormous
  - DPDK disables the interrupt, using user-space polling mode driver


- **Rings**
  - Each object in the ring is a packet descriptor which is associated with the packet buffer
  - reading the descriptor NIC can obtain the actual location of the packet in memory
  - PMD completes the interaction between the NIC and CPU by reading and writing the descriptor.
  - ring buffer to manage the queue of packets received, and the ring buffer stores fixed length descriptors of incoming packet, rather than storing the actual packet

- **The reason why using descriptor**
  - DPDK uses descriptor controlling NIC to send and receive packets, a comparison made with using the entire buffer as a circular queue.
  - Applications could maintain received packets until explicitly been freed
  - Buffer is shared by sending and receiving packet, therefore received packets can be sent directly without copied
  - **While the NIC send or receive packets the descriptor must be written back to the ring, this increases DMA operation and causes excessive DMA overhead as well as a waste of PCIe bandwidth**



- **proposing Alternative Minimum Overhead DMA**
  - **previous version**
    - in the process of sending and receiving messages we need to write back to the descriptor.
    - resulted in excess DMA operation and caused unnecessary waste of bandwidth

  - **new version**
  - after receiving the or sending messages we do not write back to the descriptor information.
  - When NIC receives a packet, we put the additional information in front of the data packet and do not write the additional information back to the descriptor.
  - When NIC send a packet, we do not write back any information to the host, and judge whether the corresponding data has been sent by the position of the pointer to description
  - using descriptors and packets sending together to improve the utilization of PCIe bandwidth.
  
